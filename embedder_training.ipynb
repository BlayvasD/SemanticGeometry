{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36e96a4-9dc9-4894-8af5-42ae5db0be04",
   "metadata": {},
   "source": [
    "# Embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26246fff-f8fa-4bab-a38b-2e87b5a3fd3e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c678f5-f3b8-4223-bff0-2aa5b7bdf6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\anaconda3\\envs\\p39_v2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import subprocess\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a058eb3-4ff1-4804-b86b-70488987c30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f954e8-9d96-4704-9813-e06537bf6363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download script\n",
      "Downloading datasets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"datasets/DATASET-NAME\"):\n",
    "    print(\"Starting download script\")\n",
    "    output = subprocess.check_output([\"python\", \"download_datasets.py\"])\n",
    "    print(output.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe6cab-81d2-4e71-995a-d4c8ebe9c7dd",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f5dce7-1d26-42fa-9dc4-79d906521169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\p39_v2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc131f16-4096-4211-aa2c-32169d25deeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\anaconda3\\envs\\p39_v2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'salient_span_wikipedia',\n",
       " 'wiki40b',\n",
       " 'wiki_auto',\n",
       " 'wiki_bio',\n",
       " 'wiki_dialog',\n",
       " 'wiki_table_questions',\n",
       " 'wiki_table_text',\n",
       " 'wikiann',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in tfds.list_builders() if 'wiki' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a04a0-47ca-4e79-bb87-60451979933c",
   "metadata": {},
   "source": [
    "Dataset of choice:\n",
    "https://www.tensorflow.org/datasets/catalog/wiki_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7140888b-f060-40b1-b006-4150e903995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = tfds.builder('wiki_auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dfed151-f1f6-4a49-9357-3a33348a6927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 53.47 MiB (download: 53.47 MiB, generated: 76.87 MiB, total: 130.34 MiB) to C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/4 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...:  25%|██▌       | 1/4 [00:00<00:02,  1.02 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]/s]\u001b[A\n",
      "Dl Size...:  50%|█████     | 2/4 [00:01<00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...:  29%|██▊       | 2/7 [00:01<00:02,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...:  43%|████▎     | 3/7 [00:01<00:02,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...:  57%|█████▋    | 4/7 [00:01<00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...:  71%|███████▏  | 5/7 [00:01<00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...:  86%|████████▌ | 6/7 [00:01<00:00,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 100%|██████████| 7/7 [00:01<00:00,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 8 MiB [00:01,  2.00 MiB/s]                     \u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 9 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 10 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 11 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 12 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 13 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 14 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 15 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 16 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 17 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 18 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 19 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 20 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 21 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 22 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 23 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 24 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 25 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 26 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 27 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 28 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 29 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 30 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 31 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 32 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 33 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 34 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 35 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 36 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 37 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 38 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 39 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 40 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 41 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 42 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 43 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 44 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 45 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 46 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 47 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 48 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 49 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 50 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 51 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:01<?, ? url/s]\n",
      "Dl Size...: 52 MiB [00:01,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 1/2 [00:02<00:02,  2.02s/ url]\n",
      "Dl Size...: 52 MiB [00:02,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 2/2 [00:02<00:00,  2.02s/ url]\n",
      "Dl Size...: 52 MiB [00:02,  2.00 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 0 file [00:02, ? file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 52 MiB [00:02, 24.93 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 2/2 [00:02<00:00,  1.04s/ url]\n",
      "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]\n",
      "Generating dev examples...:   0%|          | 0/73249 [00:00<?, ? examples/s]\u001b[A\n",
      "Generating dev examples...:   9%|▉         | 6691/73249 [00:01<00:09, 6684.94 examples/s]\u001b[A\n",
      "Generating dev examples...:  18%|█▊        | 13490/73249 [00:02<00:08, 6748.40 examples/s]\u001b[A\n",
      "Generating dev examples...:  28%|██▊       | 20252/73249 [00:03<00:07, 6751.81 examples/s]\u001b[A\n",
      "Generating dev examples...:  37%|███▋      | 27004/73249 [00:04<00:06, 6738.83 examples/s]\u001b[A\n",
      "Generating dev examples...:  46%|████▌     | 33843/73249 [00:05<00:05, 6772.68 examples/s]\u001b[A\n",
      "Generating dev examples...:  56%|█████▌    | 40660/73249 [00:06<00:04, 6785.64 examples/s]\u001b[A\n",
      "Generating dev examples...:  65%|██████▍   | 47519/73249 [00:07<00:03, 6807.58 examples/s]\u001b[A\n",
      "Generating dev examples...:  74%|███████▍  | 54359/73249 [00:08<00:02, 6815.92 examples/s]\u001b[A\n",
      "Generating dev examples...:  84%|████████▎ | 61227/73249 [00:09<00:01, 6830.25 examples/s]\u001b[A\n",
      "Generating dev examples...:  93%|█████████▎| 68131/73249 [00:10<00:00, 6851.08 examples/s]\u001b[A\n",
      "                                                                                          \u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-dev.tfrecord*...:   0%|          | 0/73249 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-dev.tfrecord*...:   8%|▊         | 5583/73249 [00:00<00:01, 55779.25 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-dev.tfrecord*...:  19%|█▉        | 13958/73249 [00:00<00:00, 72187.85 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-dev.tfrecord*...:  31%|███       | 22430/73249 [00:00<00:00, 77875.22 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-dev.tfrecord*...:  42%|████▏     | 30946/73249 [00:00<00:00, 80720.76 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-dev.tfrecord*...:  53%|█████▎    | 39185/73249 [00:00<00:00, 81295.76 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-dev.tfrecord*...:  65%|██████▍   | 47485/73249 [00:00<00:00, 81849.56 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-dev.tfrecord*...:  77%|███████▋  | 56073/73249 [00:00<00:00, 83141.75 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-dev.tfrecord*...:  88%|████████▊ | 64601/73249 [00:00<00:00, 83797.79 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-dev.tfrecord*...: 100%|█████████▉| 72981/73249 [00:00<00:00, 83513.66 examples/s]\u001b[A\n",
      "Generating splits...:  50%|█████     | 1/2 [00:11<00:11, 11.74s/ splits]                                                                                                        \u001b[A\n",
      "Generating test examples...:   0%|          | 0/118074 [00:00<?, ? examples/s]\u001b[A\n",
      "Generating test examples...:   6%|▌         | 6889/118074 [00:01<00:16, 6882.75 examples/s]\u001b[A\n",
      "Generating test examples...:  12%|█▏        | 13849/118074 [00:02<00:15, 6924.48 examples/s]\u001b[A\n",
      "Generating test examples...:  18%|█▊        | 20839/118074 [00:03<00:13, 6951.50 examples/s]\u001b[A\n",
      "Generating test examples...:  24%|██▎       | 27830/118074 [00:04<00:12, 6964.59 examples/s]\u001b[A\n",
      "Generating test examples...:  29%|██▉       | 34803/118074 [00:05<00:11, 6965.34 examples/s]\u001b[A\n",
      "Generating test examples...:  35%|███▌      | 41769/118074 [00:06<00:11, 6935.12 examples/s]\u001b[A\n",
      "Generating test examples...:  41%|████      | 48705/118074 [00:07<00:10, 6913.07 examples/s]\u001b[A\n",
      "Generating test examples...:  47%|████▋     | 55619/118074 [00:08<00:09, 6893.89 examples/s]\u001b[A\n",
      "Generating test examples...:  53%|█████▎    | 62528/118074 [00:09<00:08, 6896.64 examples/s]\u001b[A\n",
      "Generating test examples...:  59%|█████▉    | 69449/118074 [00:10<00:07, 6902.21 examples/s]\u001b[A\n",
      "Generating test examples...:  65%|██████▍   | 76375/118074 [00:11<00:06, 6907.55 examples/s]\u001b[A\n",
      "Generating test examples...:  71%|███████   | 83283/118074 [00:12<00:05, 6901.59 examples/s]\u001b[A\n",
      "Generating test examples...:  76%|███████▋  | 90210/118074 [00:13<00:04, 6907.38 examples/s]\u001b[A\n",
      "Generating test examples...:  82%|████████▏ | 97165/118074 [00:14<00:03, 6919.84 examples/s]\u001b[A\n",
      "Generating test examples...:  88%|████████▊ | 104085/118074 [00:15<00:02, 6903.44 examples/s]\u001b[A\n",
      "Generating test examples...:  94%|█████████▍| 111034/118074 [00:16<00:01, 6915.24 examples/s]\u001b[A\n",
      "Generating test examples...: 100%|█████████▉| 117950/118074 [00:17<00:00, 6853.90 examples/s]\u001b[A\n",
      "                                                                                             \u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:   0%|          | 0/118074 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:   2%|▏         | 2762/118074 [00:00<00:04, 27595.03 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  10%|▉         | 11246/118074 [00:00<00:01, 61223.24 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  17%|█▋        | 19714/118074 [00:00<00:01, 71899.11 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  24%|██▎       | 27947/118074 [00:00<00:01, 75987.57 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  31%|███       | 36137/118074 [00:00<00:01, 78092.93 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  38%|███▊      | 44364/118074 [00:00<00:00, 79487.65 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  44%|████▍     | 52313/118074 [00:00<00:00, 79464.92 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  51%|█████▏    | 60539/118074 [00:00<00:00, 80330.94 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  58%|█████▊    | 68943/118074 [00:00<00:00, 81466.57 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  65%|██████▌   | 77205/118074 [00:01<00:00, 81799.59 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  72%|███████▏  | 85385/118074 [00:01<00:00, 81279.52 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  79%|███████▉  | 93581/118074 [00:01<00:00, 81463.14 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  86%|████████▌ | 101728/118074 [00:01<00:00, 81442.85 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0.incompleteA7DHTK\\wiki_auto-test.tfrecord*...:  93%|█████████▎| 109986/118074 [00:01<00:00, 81763.04 examples/s]\u001b[A\n",
      "                                                                                                                                                                                   \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset wiki_auto downloaded and prepared to C:\\Users\\David\\tensorflow_datasets\\wiki_auto\\manual\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# 1. Create the tfrecord files (no-op if already exists)\n",
    "builder.download_and_prepare(download_dir=\"datasets/wiki_auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91696961-6e30-454d-b67f-eb1ddae2de45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dev': <_PrefetchDataset element_spec={'GLEU-score': TensorSpec(shape=(), dtype=tf.float64, name=None), 'alignment_label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'normal_sentence': TensorSpec(shape=(), dtype=tf.string, name=None), 'normal_sentence_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'simple_sentence': TensorSpec(shape=(), dtype=tf.string, name=None), 'simple_sentence_id': TensorSpec(shape=(), dtype=tf.string, name=None)}>,\n",
       " 'test': <_PrefetchDataset element_spec={'GLEU-score': TensorSpec(shape=(), dtype=tf.float64, name=None), 'alignment_label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'normal_sentence': TensorSpec(shape=(), dtype=tf.string, name=None), 'normal_sentence_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'simple_sentence': TensorSpec(shape=(), dtype=tf.string, name=None), 'simple_sentence_id': TensorSpec(shape=(), dtype=tf.string, name=None)}>}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Load the `tf.data.Dataset`\n",
    "dataset = builder.as_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "768385e9-477b-4bf9-afd9-34bf5492013e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec={'GLEU-score': TensorSpec(shape=(), dtype=tf.float64, name=None), 'alignment_label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'normal_sentence': TensorSpec(shape=(), dtype=tf.string, name=None), 'normal_sentence_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'simple_sentence': TensorSpec(shape=(), dtype=tf.string, name=None), 'simple_sentence_id': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devset = dataset['dev']\n",
    "devset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b6ed694-a8e1-4364-8bef-97388c709abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec={'GLEU-score': TensorSpec(shape=(), dtype=tf.float64, name=None), 'alignment_label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'normal_sentence': TensorSpec(shape=(), dtype=tf.string, name=None), 'normal_sentence_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'simple_sentence': TensorSpec(shape=(), dtype=tf.string, name=None), 'simple_sentence_id': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = devset.take(10)  # Take a few examples\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50f45680-6a62-44a2-852a-704f887fdea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t b'For example, in the petroleum industry, sodium hydroxide is used as an additive in drilling mud to increase alkalinity in bentonite mud systems, to increase the mud viscosity, and to neutralize any acid gas (such as hydrogen sulfide and carbon dioxide) which may be encountered in the geological formation as drilling progresses.'\n",
      "\t b'Emer O\\'Sullivan, in her \"Comparative Children\\'s Literature\", notes \"The Hobbit\" as one of a handful of children\\'s books that have been accepted into mainstream literature, alongside Jostein Gaarder\\'s \"Sophie\\'s World\" (1991) and J. K. Rowling\\'s \"Harry Potter\" series (1997\\xe2\\x80\\x932007).'\n",
      "\t b'When certain liquids needs to be purified, siphoning can help prevent either the bottom (dregs) or the top (foam and floaties) from being transferred out of one container into a new container.'\n",
      "\t b'Originally this world was self-contained, but as Tolkien began work on \"The Lord of the Rings\", he decided these stories could fit into the legendarium he had been working on privately for decades.'\n",
      "\t b'This resulted in sabotage acts directed towards the bikers as well as the publication of several provocative manuscripts urging the Christianites to throw out the powerful and armed bikers.'\n",
      "\t b'The main purchasers of munitions from the big three companies were Romania, Yugoslavia, Greece, and Turkey-- and, to a lesser extent, in Poland, Finland, the Baltic States, and the Soviet Union,'\n",
      "\t b'The Dutch sold the fort to king Ali Raja of Arakkal in 1772.'\n",
      "\t b'The Airborne, Thunderbolt, and Republican Guard units each utilize their own camouflaged uniforms.'\n",
      "\t b'The additional illustrations proved so appealing that George Allen & Unwin adopted the colour plates as well for their second printing, with exception of \"Bilbo Woke Up with the Early Sun in His Eyes\".'\n",
      "\t b'The introduction of gunpowder from the Asia at the end of this period revolutionized warfare.'\n"
     ]
    }
   ],
   "source": [
    "for e in examples:\n",
    "    print(\"\\t\", e['normal_sentence'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610e353-5608-4f96-a9df-04c580edebe4",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8284835c-bab6-46a9-aac0-e1dd791c703c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257ce789-2a9c-428d-afb3-558084d21e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "916cf270-1374-414d-9eaf-90e0e4890e16",
   "metadata": {},
   "source": [
    "---\n",
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9203e247-f7a6-4b15-91f3-153d03ac62b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f3343-1d0a-4bf2-be11-7dd3dabfd3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe011b12-b2d6-4ff4-8e33-dcce282e05b2",
   "metadata": {},
   "source": [
    "---\n",
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05988149-0c4b-4b6e-abb9-cadc0146d419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1dd580-e353-42fc-9819-a077651c62c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
